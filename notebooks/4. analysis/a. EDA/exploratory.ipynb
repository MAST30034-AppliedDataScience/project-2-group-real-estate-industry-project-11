{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import GeoJson\n",
    "from math import log\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../../../scripts/2. modules'))\n",
    "import processing\n",
    "\n",
    "# Inputs\n",
    "HISTORICAL_DATA_PATH = '../../../data/3. curated/merged/all_historical_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv(HISTORICAL_DATA_PATH)\n",
    "regions_df = processing.get_regions_df(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca\n",
    "\n",
    "def filter_range(input_df, start_year, start_quarter, end_year, end_quarter, house_type=None, bedrooms=None):\n",
    "        \n",
    "    if (house_type and not bedrooms) or (bedrooms and not house_type):\n",
    "        raise ValueError(f\"Either both or neither of house_type or bedrooms must be None\")\n",
    "    \n",
    "    house_filter = (input_df['housing: type'] == house_type) if house_type else (input_df['housing: type'] == 'all')\n",
    "    room_filter = (input_df['housing: beds'] == bedrooms) if bedrooms else (input_df['housing: beds'] == 'all')\n",
    "\n",
    "    if start_year == end_year:\n",
    "        return input_df[\n",
    "            (input_df['year'] == start_year) & (input_df['quarter'] >= start_quarter) \n",
    "            & (input_df['quarter'] <= end_quarter) & \n",
    "            house_filter & room_filter\n",
    "        ].copy()\n",
    "    else:\n",
    "        return input_df[\n",
    "            (((input_df['year'] > start_year) & (input_df['year'] < end_year)) | \n",
    "            ((input_df['year'] == start_year) & (input_df['quarter'] >= start_quarter)) | \n",
    "            ((input_df['year'] == end_year) & (input_df['quarter'] <= end_quarter))) & \n",
    "            house_filter & room_filter\n",
    "        ].copy()\n",
    "\n",
    "def standardize(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "def visualize_on_map(input_df, display_col, year, quarter, house_type=None, bedrooms=None, transform=None, map_location=[-37.8136, 144.9631], zoom_start=10,\n",
    "                     min_val=None, max_val=None, color_scale_label=\"\"):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a GeoDataFrame based on the specified geometry column,\n",
    "    and display it on a Folium map with the specified column as popups.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    geometry_col (str): The name of the geometry column.\n",
    "    display_col (str): The name of the column to display in popups.\n",
    "    map_location (list): Latitude and longitude for centering the map [lat, lon].\n",
    "    zoom_start (int): Initial zoom level for the map.\n",
    "\n",
    "    Returns:\n",
    "    folium.Map: The Folium map with the GeoDataFrame visualized.\n",
    "    \"\"\"\n",
    "\n",
    "    if (house_type and not bedrooms) or (bedrooms and not house_type):\n",
    "        raise ValueError(f\"Either both or neither of house_type or bedrooms must be None\")\n",
    "    \n",
    "    house_filter = (input_df['housing: type'] == house_type) if house_type else (input_df['housing: type'] == 'all')\n",
    "    room_filter = (input_df['housing: beds'] == bedrooms) if bedrooms else (input_df['housing: beds'] == 'all')\n",
    "\n",
    "    input_df_filtered = input_df[(input_df['year'] == year) & (input_df['quarter'] == quarter)\n",
    "                                 & house_filter & room_filter]\n",
    "\n",
    "    df = pd.merge(regions_df, input_df_filtered, on='suburbs').dropna(subset=[display_col])\n",
    "\n",
    "    # if max_val:\n",
    "    #     df[display_col] = df[display_col].clip(upper=max_val)\n",
    "\n",
    "    if transform:\n",
    "        if transform == 'std':\n",
    "            mean_value = df['housing: median'].mean()\n",
    "            std_dev_value = df['housing: median'].std()\n",
    "\n",
    "            df[display_col] = df[display_col].apply(lambda x : (x - mean_value) / std_dev_value)\n",
    "        else:\n",
    "            df[display_col] = df[display_col].apply(transform)\n",
    "    \n",
    "    # Create a GeoDataFrame using the geometry column\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=df['geometry'])\n",
    "    \n",
    "    # Check if the display column exists\n",
    "    if display_col not in gdf.columns:\n",
    "        raise ValueError(f\"Column '{display_col}' not found in the GeoDataFrame.\")\n",
    "    \n",
    "    # Create a color scale\n",
    "    if not min_val:\n",
    "        min_val = gdf[display_col].min()\n",
    "    \n",
    "    if not max_val:\n",
    "        max_val = gdf[display_col].max()\n",
    "    colormap = branca.colormap.LinearColormap(colors=['#440154', '#482878', '#3E4A89', '#2D708E', '#21918C', '#5CDB8A', '#FDE724'], \n",
    "                                                    vmin=min_val, vmax=max_val, caption=color_scale_label)\n",
    "\n",
    "    # Convert GeoDataFrame to GeoJSON format\n",
    "    geojson_data = gdf.to_json()\n",
    "\n",
    "    # Create a Folium map centered at the specified location\n",
    "    m = folium.Map(location=map_location, zoom_start=zoom_start)\n",
    "\n",
    "    # Function to create a style for the GeoJSON\n",
    "    def style_function(feature):\n",
    "        value = feature['properties'][display_col]\n",
    "        return {\n",
    "            'fillColor': colormap(value),  # Use the color scale\n",
    "            'color': 'black',\n",
    "            'weight': 1,\n",
    "            'fillOpacity': 0.5\n",
    "        }\n",
    "\n",
    "    # Add GeoJSON to the map with popups\n",
    "    GeoJson(\n",
    "        geojson_data,\n",
    "        style_function=style_function,\n",
    "        tooltip=folium.GeoJsonTooltip(fields=[display_col], aliases=[display_col.capitalize()])\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add color scale to the map\n",
    "    colormap.add_to(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We being by doing a naieve exploration of the correlation of each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../../../data/4. analysis/correlation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m CORRELATIONS_OUTPUT_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../data/4. analysis/correlation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCORRELATIONS_OUTPUT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m MEDIAN_IMPUTE \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousing: count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_school_median_study_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_school_number_vce_subjects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_school_median_study_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_school_satisfactory_complete_vce_percent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousing: median\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_school_percentage_applying_to_victorian_uni\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_school_number_vce_subjects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_school_satisfactory_complete_vce_percent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_school_percentage_applying_to_victorian_uni\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m DWELLING_COMBINATIONS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m ]\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '../../../data/4. analysis/correlation'"
     ]
    }
   ],
   "source": [
    "CORRELATIONS_OUTPUT_PATH = '../../../data/4. analysis/correlation'\n",
    "os.makedirs(CORRELATIONS_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "MEDIAN_IMPUTE = ['housing: count', 'avg_school_median_study_score', 'best_school_number_vce_subjects', 'best_school_median_study_score', 'avg_school_satisfactory_complete_vce_percent', 'housing: median', 'best_school_percentage_applying_to_victorian_uni', 'avg_school_number_vce_subjects', 'best_school_satisfactory_complete_vce_percent', 'avg_school_percentage_applying_to_victorian_uni']\n",
    "\n",
    "DWELLING_COMBINATIONS = [\n",
    "    ('house', '2'), ('house', '3'), ('house', '4'), ('flat', '1'), ('flat', '2'), ('flat', '3'), ('all', 'all')\n",
    "]\n",
    "\n",
    "for comb in DWELLING_COMBINATIONS:\n",
    "\n",
    "    df_filtered = filter_range(housing_df, 2016, 3, 2019, 4, comb[0], comb[1])\n",
    "\n",
    "    numeric_columns = df_filtered.select_dtypes(include=['number']).columns\n",
    "\n",
    "    for col in MEDIAN_IMPUTE:\n",
    "        median = df_filtered[col].median()\n",
    "        df_filtered[col].fillna(median, inplace=True)\n",
    "\n",
    "    # Then, filter those columns based on non-missing values\n",
    "    numeric_non_missing_cols = [col for col in numeric_columns if df_filtered[col].notna().all() and col != 'housing: median']\n",
    "\n",
    "    correlations = []\n",
    "\n",
    "    for col in numeric_non_missing_cols:\n",
    "        if col not in ('housing: median', 'duration_to_cbd'):\n",
    "            correlations.append((col, float(df_filtered[['housing: median', col]].corr(method='pearson').loc['housing: median', col]),\n",
    "                                float(df_filtered[['duration_to_cbd', col]].corr(method='pearson').loc['duration_to_cbd', col])))\n",
    "\n",
    "    pd.DataFrame(correlations, columns=['variable', 'correlation', 'correlation_with_distance']).sort_values('correlation').to_csv(f'{CORRELATIONS_OUTPUT_PATH}/{comb[0]}{comb[1]}correlations.csv')\n",
    "\n",
    "# list(sorted(correlations, key=lambda x: x[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
