{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIVE_PATH_IN_CURATED = \"../../../data/3. curated\"\n",
    "RELATIVE_PATH_IN_MODELLING = \"../../../data/4. modelling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6228, 181)\n"
     ]
    }
   ],
   "source": [
    "curated_raw = pd.read_csv(f\"{RELATIVE_PATH_IN_CURATED}/external prices.csv\", index_col=0)\n",
    "print(curated_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frame(df, type=False, start_year=False, end_year=False):\n",
    "    df_mask = pd.Series(data=True, index=df.index)\n",
    "    if (type):\n",
    "        df_mask = df_mask & (df[\"housing: type\"] == type)\n",
    "    \n",
    "    if (start_year):\n",
    "        df_mask = df_mask & (df[\"year groups\"] >= start_year)\n",
    "    if (end_year):\n",
    "        df_mask = df_mask & (df[\"year groups\"] <= end_year)\n",
    "    \n",
    "    return df[df_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6228, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>economic: median income</th>\n",
       "      <th>economic: median age of earners</th>\n",
       "      <th>economic: gini coefficient</th>\n",
       "      <th>economic: variable interest rate</th>\n",
       "      <th>economic: gdp per capita quarterly</th>\n",
       "      <th>economic: trimmed mean quarterly</th>\n",
       "      <th>economic: number of earners</th>\n",
       "      <th>economic: net inflation</th>\n",
       "      <th>economic: variable interest rate growth</th>\n",
       "      <th>housing: type</th>\n",
       "      <th>...</th>\n",
       "      <th>studying: tertiary total (%)</th>\n",
       "      <th>studying: tafe total (%)</th>\n",
       "      <th>studying: primary government (%)</th>\n",
       "      <th>studying: primary total (%)</th>\n",
       "      <th>distance: crow distance to cbd</th>\n",
       "      <th>distance: distance to cbd</th>\n",
       "      <th>distance: crow distance to cbd inv</th>\n",
       "      <th>distance: distance to cbd inv</th>\n",
       "      <th>suburbs</th>\n",
       "      <th>year groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63415.3</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>6.3825</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.675</td>\n",
       "      <td>21731.8</td>\n",
       "      <td>1.044823</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>flat</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>4.535857</td>\n",
       "      <td>6702.5</td>\n",
       "      <td>0.081735</td>\n",
       "      <td>0.211996</td>\n",
       "      <td>Albert Park-Middle Park-West St Kilda</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63415.3</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>6.6325</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.675</td>\n",
       "      <td>21731.8</td>\n",
       "      <td>1.073584</td>\n",
       "      <td>0.039</td>\n",
       "      <td>flat</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>4.535857</td>\n",
       "      <td>6702.5</td>\n",
       "      <td>0.081735</td>\n",
       "      <td>0.211996</td>\n",
       "      <td>Albert Park-Middle Park-West St Kilda</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63415.3</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>7.0700</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.675</td>\n",
       "      <td>21731.8</td>\n",
       "      <td>1.102315</td>\n",
       "      <td>0.066</td>\n",
       "      <td>flat</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>4.535857</td>\n",
       "      <td>6702.5</td>\n",
       "      <td>0.081735</td>\n",
       "      <td>0.211996</td>\n",
       "      <td>Albert Park-Middle Park-West St Kilda</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   economic: median income  economic: median age of earners  \\\n",
       "0                  63415.3                             39.8   \n",
       "1                  63415.3                             39.8   \n",
       "2                  63415.3                             39.8   \n",
       "\n",
       "   economic: gini coefficient  economic: variable interest rate  \\\n",
       "0                      0.5565                            6.3825   \n",
       "1                      0.5565                            6.6325   \n",
       "2                      0.5565                            7.0700   \n",
       "\n",
       "   economic: gdp per capita quarterly  economic: trimmed mean quarterly  \\\n",
       "0                               0.625                             0.675   \n",
       "1                               0.725                             0.675   \n",
       "2                               0.475                             0.675   \n",
       "\n",
       "   economic: number of earners  economic: net inflation  \\\n",
       "0                      21731.8                 1.044823   \n",
       "1                      21731.8                 1.073584   \n",
       "2                      21731.8                 1.102315   \n",
       "\n",
       "   economic: variable interest rate growth housing: type  ...  \\\n",
       "0                                   -0.070          flat  ...   \n",
       "1                                    0.039          flat  ...   \n",
       "2                                    0.066          flat  ...   \n",
       "\n",
       "   studying: tertiary total (%)  studying: tafe total (%)  \\\n",
       "0                        0.0637                    0.0236   \n",
       "1                        0.0637                    0.0236   \n",
       "2                        0.0637                    0.0236   \n",
       "\n",
       "   studying: primary government (%)  studying: primary total (%)  \\\n",
       "0                            0.0336                       0.0436   \n",
       "1                            0.0336                       0.0436   \n",
       "2                            0.0336                       0.0436   \n",
       "\n",
       "   distance: crow distance to cbd  distance: distance to cbd  \\\n",
       "0                        4.535857                     6702.5   \n",
       "1                        4.535857                     6702.5   \n",
       "2                        4.535857                     6702.5   \n",
       "\n",
       "   distance: crow distance to cbd inv  distance: distance to cbd inv  \\\n",
       "0                            0.081735                       0.211996   \n",
       "1                            0.081735                       0.211996   \n",
       "2                            0.081735                       0.211996   \n",
       "\n",
       "                                 suburbs  year groups  \n",
       "0  Albert Park-Middle Park-West St Kilda          2.0  \n",
       "1  Albert Park-Middle Park-West St Kilda          3.0  \n",
       "2  Albert Park-Middle Park-West St Kilda          4.0  \n",
       "\n",
       "[3 rows x 121 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_columns(df, find=[], avoid=[], require_all=False):\n",
    "    curr_columns = df.columns\n",
    "    \n",
    "    # filter any columns that contain the find_sub\n",
    "    if (find):\n",
    "        if (not require_all):\n",
    "            curr_columns = [column for column in curr_columns if any(sub in column for sub in find)]\n",
    "        else:\n",
    "            curr_columns = [column for column in curr_columns if all(sub in column for sub in find)]\n",
    "\n",
    "    # avoid any columns that contain the avoid_sub\n",
    "    curr_columns = [column for column in curr_columns if all(not sub in column for sub in avoid)]\n",
    "\n",
    "    return curr_columns\n",
    "\n",
    "FEATURES = filter_columns(curated_raw, find=[\"economic:\"], avoid=[\"%\", \"gdp quarterly\"]) + \\\n",
    "           filter_columns(curated_raw, find=[\"housing:\"]) + \\\n",
    "           filter_columns(curated_raw, find=[\"overseas:\"]) + \\\n",
    "           filter_columns(curated_raw, find=[\"population:\"]) + \\\n",
    "           filter_columns(curated_raw, find=[\"relationships:\"]) + \\\n",
    "           filter_columns(curated_raw, find=[\"studying:\"], avoid=[\"PT\", \"FT\"]) + \\\n",
    "           filter_columns(curated_raw, find=[\"distance:\"]) + \\\n",
    "           [\"suburbs\", \"year groups\"]\n",
    "\n",
    "curated = curated_raw[FEATURES]\n",
    "\n",
    "print(curated.shape)\n",
    "curated.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Linearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COLUMN = \"housing: median growth avg\"\n",
    "\n",
    "def plot_subset(df, find=False, name=\"pairplot.png\", display=True, root=False):\n",
    "    y_column = Y_COLUMN\n",
    "\n",
    "    if (find):\n",
    "        print(f\"using \\\"{find}\\\" to filter\")\n",
    "\n",
    "        # get the filtered df\n",
    "        df = df.copy()\n",
    "        df = df[filter_columns(df, find=[find, y_column])]\n",
    "\n",
    "    # print the shape and ask to continue\n",
    "    response = input(f\"frame has {df.shape[1] - 1} columns, wish to proceed? (y)\")\n",
    "    if (response.lower() != \"y\"):\n",
    "        return\n",
    "\n",
    "    print(filter_columns(df, avoid=[y_column]))\n",
    "\n",
    "    # graph\n",
    "    sns.set_style('white')\n",
    "    pairplot = sns.pairplot(df, y_vars=y_column, x_vars=list(set(df.columns) - set([y_column])), diag_kind=None)# #plot_kws={'alpha': 0.6})\n",
    "\n",
    "    # save and show\n",
    "    if (display):\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \"distance:\" to filter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \"distance:\" to filter\n"
     ]
    }
   ],
   "source": [
    "plot_subset(filter_frame(curated, type=\"house\"), \"distance:\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\"), \"distance:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \"housing:\" to filter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \"housing:\" to filter\n"
     ]
    }
   ],
   "source": [
    "plot_subset(filter_frame(curated, type=\"house\"), \"housing:\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\"), \"housing:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population (not total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_COLUMNS = filter_columns(curated, find=[\"population: \", \"growth\"], require_all=True) + filter_columns(curated, find=[\"housing: median growth\"])\n",
    "\n",
    "plot_subset(filter_frame(curated, type=\"house\")[POP_COLUMNS], name=\"population house\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\")[POP_COLUMNS], name=\"population flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_COLUMNS = filter_columns(curated, find=[\"population: \", \"total\"], require_all=True) + filter_columns(curated, find=[\"housing: median growth\"])\n",
    "\n",
    "plot_subset(filter_frame(curated, type=\"house\")[POP_COLUMNS], name=\"population total house\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\")[POP_COLUMNS], name=\"population total flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_COLUMNS = filter_columns(curated, find=[\"study\", \"%\"], require_all=True) + filter_columns(curated, find=[\"housing: median growth\"])\n",
    "\n",
    "plot_subset(filter_frame(curated, type=\"house\", start_year=22, end_year=23)[STUDY_COLUMNS], name=\"study house\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\", start_year=22, end_year=23)[STUDY_COLUMNS], name=\"study flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIONSHIPS_COLUMNS = filter_columns(curated, find=[\"relationships\", \"%\"], require_all=True) + filter_columns(curated, find=[\"housing: median growth\"])\n",
    "\n",
    "plot_subset(filter_frame(curated, type=\"house\", start_year=22, end_year=23)[RELATIONSHIPS_COLUMNS], name=\"relationships house\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\", start_year=22, end_year=23)[RELATIONSHIPS_COLUMNS], name=\"relationships flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECONOMIC_COLUMNS = filter_columns(curated, find=[\"economic: \"], require_all=True) + filter_columns(curated, find=[\"housing: median growth\"])\n",
    "\n",
    "plot_subset(filter_frame(curated, type=\"house\", start_year=22, end_year=23)[ECONOMIC_COLUMNS], name=\"relationships house\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\", start_year=22, end_year=23)[ECONOMIC_COLUMNS], name=\"relationships flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overseas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERSEAS_COLUMNS = filter_columns(curated, find=[\"oversea\"], require_all=True) + filter_columns(curated, find=[\"housing: median growth\"])\n",
    "\n",
    "plot_subset(filter_frame(curated, type=\"house\", start_year=22, end_year=23)[OVERSEAS_COLUMNS], name=\"overseas house\")\n",
    "plot_subset(filter_frame(curated, type=\"flat\", start_year=22, end_year=23)[OVERSEAS_COLUMNS], name=\"overseas flat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out spots less than 200 (to noisy)\n",
    "curated = curated[curated[\"housing: count\"] >= 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the log transforms\n",
    "LOG_FEATURES = [\"housing: previous count\", \"housing: count\"] + \\\n",
    "               [\"studying: tertiary total (%)\", \"studying: primary other (%)\", \"studying: tafe total (%)\"] + \\\n",
    "               [\"economic: number of earners\"] + \\\n",
    "               [\"population: total\"] + \\\n",
    "               [\"overseas: 5 years (%)\"] + \\\n",
    "               [\"distance: distance to cbd\", \"distance: crow distance to cbd\"]\n",
    "\n",
    "curated_final = curated.copy()\n",
    "for feature in LOG_FEATURES:\n",
    "    curated_final.loc[:, feature + \" log\"] = curated[feature].apply(np.log)\n",
    "    curated_final.rename(columns={feature: feature + \" norm\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset(filter_frame(curated_final, type=\"house\")[filter_columns(curated_final, find=[\"log\", \"housing: median\"])], name=\"transformation housing\", root=False)\n",
    "plot_subset(filter_frame(curated_final, type=\"flat\")[filter_columns(curated_final, find=[\"log\", \"housing: median\"])], name=\"transformation flat\", root=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction(df, interaction_pairs):\n",
    "    # get all the interaction pairs\n",
    "    for column_1, column_2 in interaction_pairs:\n",
    "        new_name = f\"interaction: ({column_1}) & ({column_2})\"\n",
    "        df[new_name] = df[column_1] * df[column_2]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_COLUMNS = filter_columns(curated_final, [\"population: \", \"growth\", \"0\", \"9\"], [\"interaction\"], require_all=True) + filter_columns(curated_final, [\"population:\", \"total\"], [\"norm\", \"interaction\"], require_all=True)\n",
    "\n",
    "# will get interaction between\n",
    "# - all population growths and distance / median income\n",
    "# - quarterly growths with distance / median income\n",
    "# - all population growths and teritary\n",
    "interaction_pairs = [(x, y) for x in filter_columns(curated_final, [\"distance:\", \"economic: median income\"], [\"inv\", \"norm\", \"interaction\"]) for y in POP_COLUMNS] + \\\n",
    "                    [(x, y) for x in filter_columns(curated_final, [\"distance:\", \"economic: median income\"], [\"inv\", \"norm\", \"interaction\"]) for y in ['economic: trimmed mean quarterly', 'economic: gdp per capita quarterly']] + \\\n",
    "                    [(x, y) for x in filter_columns(curated_final, [\"studying:\", \"tertiary\", \"log\"], [\"interaction\"], require_all=True) for y in POP_COLUMNS]\n",
    "\n",
    "curated_final = get_interaction(curated_final, interaction_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### FOR all variables that can actually work ###########\n",
    "\n",
    "# include the following\n",
    "# - information about the region that doesn't change (economic)\n",
    "# - types of beds and the previous, price growth, count growth, log count, price\n",
    "# - number of people overseas 5 years ago\n",
    "# - population growth by each demographic\n",
    "# - population total count log\n",
    "# - percentage of the population studying and what not\n",
    "FEATURES = filter_columns(curated_final, find=[\"housing\"], avoid=[\"norm\", \"median growth\", \"housing: count\", \"housing: median\", \"interaction\", \"avg\"]) + \\\n",
    "           POP_COLUMNS + \\\n",
    "           filter_columns(curated_final, find=[\"economic\", \"quarterly\"], avoid=[\"distance\"], require_all=True) + \\\n",
    "           filter_columns(curated_final, find=[\"interaction\", \"population\"], avoid=[\"distance\"], require_all=True)\n",
    "           \n",
    "\n",
    "CAT_FEATURES = [\"housing: type\"]\n",
    "\n",
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aic(model, X, y):\n",
    "    \"\"\"\n",
    "    Calculate the Akaike Information Criterion (AIC) for a given scikit-learn model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: A fitted scikit-learn model that implements the `predict` method.\n",
    "    - X: Features (numpy array or pandas DataFrame) used for fitting the model.\n",
    "    - y: True target values (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "    - aic: The Akaike Information Criterion value.\n",
    "    \"\"\"\n",
    "    # Ensure the model has been fitted\n",
    "    if not hasattr(model, 'predict'):\n",
    "        raise ValueError(\"The model must implement the `predict` method and be fitted.\")\n",
    "\n",
    "    # Number of observations\n",
    "    n = len(y)\n",
    "\n",
    "    # Number of parameters (coefficients + intercept)\n",
    "    if hasattr(model, 'coef_'):\n",
    "        # Linear models (e.g., LinearRegression)\n",
    "        k = model.coef_.shape[0] + 1  # Coefficients + Intercept\n",
    "    else:\n",
    "        # Other models\n",
    "        k = len(model.get_params())\n",
    "\n",
    "    # Predicted values\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Calculate residual sum of squares\n",
    "    residual_sum_of_squares = np.sum((y - y_pred) ** 2)\n",
    "\n",
    "    # Calculate AIC\n",
    "    aic = n * np.log(residual_sum_of_squares / n) + 2 * k\n",
    "    return aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection_with_validation(X_select_train, y_select_train, X_select_val, y_select_val, validation_size=0.2, random_state=42, use_aic=True):\n",
    "    \"\"\"\n",
    "    Perform forward selection using a validation set to choose the best set of features for linear regression.\n",
    "    \n",
    "    Args:\n",
    "    X: Features (DataFrame)\n",
    "    y: Target variable (Series)\n",
    "    validation_size: Fraction of data to use as validation set (default 0.2)\n",
    "    random_state: Random seed for reproducibility (default 42)\n",
    "    \n",
    "    Returns:\n",
    "    best_features: List of selected features based on validation set performance\n",
    "    final_model: Trained linear regression model using the selected features\n",
    "    \"\"\"\n",
    "\n",
    "    # Rename\n",
    "    X_train, y_train, X_val, y_val = X_select_train, y_select_train, X_select_val, y_select_val\n",
    "    \n",
    "    # Initialize variables\n",
    "    initial_features = []\n",
    "    remaining_features = list(X_train.columns)\n",
    "    best_features = []\n",
    "    best_score = float('inf')  # Start with a very high RMSE\n",
    "    \n",
    "    # Iterate through all features to add one by one\n",
    "    while remaining_features:\n",
    "        scores_with_candidates = []\n",
    "        \n",
    "        # Try adding each remaining feature to the model\n",
    "        for candidate in remaining_features:\n",
    "            # Features to include in the model\n",
    "            features_to_test = initial_features + [candidate]\n",
    "            \n",
    "            # Fit a linear regression model using the current feature set\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train[features_to_test], y_train)\n",
    "            \n",
    "            if (not use_aic):\n",
    "                # Predict and calculate RMSE on the validation set\n",
    "                y_val_pred = model.predict(X_val[features_to_test])\n",
    "                rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "                # Store the result: (rmse, feature_name)\n",
    "                scores_with_candidates.append((rmse, candidate))\n",
    "                \n",
    "            else:\n",
    "                # get the AIC\n",
    "                aic = calculate_aic(model, X_val[features_to_test], y_val)\n",
    "                scores_with_candidates.append((aic, candidate))\n",
    "        \n",
    "        # Sort by RMSE, select the best candidate feature\n",
    "        scores_with_candidates.sort(reverse=False)\n",
    "        best_new_score, best_new_feature = scores_with_candidates[0]\n",
    "        \n",
    "        # If the score improves, update the best features list\n",
    "        if best_new_score < best_score:\n",
    "            initial_features.append(best_new_feature)\n",
    "            remaining_features.remove(best_new_feature)\n",
    "            best_features = initial_features.copy()\n",
    "            best_score = best_new_score\n",
    "            #if (use_aic):\n",
    "            #    print(f\"Selected '{best_new_feature}' with AIC: {best_new_score:.4f}\")\n",
    "            #else:\n",
    "            #    print(f\"Selected '{best_new_feature}' with RMSE: {best_new_score:.4f}\")\n",
    "        else:\n",
    "            break  # Stop if adding a new feature doesn't improve the score\n",
    "    \n",
    "    return best_features, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(df, start_year, end_year=False):\n",
    "    if (not end_year):\n",
    "        mask = df[\"year groups\"] == start_year\n",
    "    else:\n",
    "        mask = ((df[\"year groups\"] >= start_year) &\n",
    "                (df[\"year groups\"] <= end_year))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_COLUMN = \"housing: median growth\"\n",
    "\n",
    "def get_data(df, start_year, end_year, test_year, features):\n",
    "\n",
    "    # remove `all`` properties\n",
    "    df_filt = df.copy()[(df[\"housing: type\"] == \"house\")] #& (curated_final[\"housing: beds\"] == \"3\")]\n",
    "    not_na_mask = ~df_filt[features + [TEST_COLUMN]].isna().any(axis=1)\n",
    "\n",
    "    # test mask\n",
    "    test_mask = get_mask(df_filt, test_year) & not_na_mask\n",
    "\n",
    "    # get the mask forward selection\n",
    "    selection_train_masks = [get_mask(df_filt, start_year, end_year=end_year-1) & not_na_mask for start_year in range(start_year, end_year)]\n",
    "    selection_val_mask = get_mask(df_filt, end_year) & not_na_mask\n",
    "\n",
    "    # get the train test features\n",
    "    X = df_filt[features]\n",
    "    y = df_filt[TEST_COLUMN]\n",
    "\n",
    "    # Step 3: One-Hot Encode the categorical features\n",
    "    X = pd.get_dummies(X, columns=list(set(CAT_FEATURES) & set(features)), drop_first=True)\n",
    "\n",
    "    # split the train and test\n",
    "    X_train, y_train, X_test, y_test = X[selection_train_masks[0]], y[selection_train_masks[0]], X[test_mask], y[test_mask]\n",
    "\n",
    "    # store in dictionary\n",
    "    data_dict = {\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test, \n",
    "        \"y_test\": y_test,\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"train_masks\": selection_train_masks,\n",
    "        \"val_mask\": selection_val_mask\n",
    "        }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, start_year, end_year, test_year, features):\n",
    "    data_dict = get_data(df, start_year, end_year, test_year, features)\n",
    "\n",
    "    # get the datasets\n",
    "    train_mask = data_dict[\"train_masks\"][0]\n",
    "    val_mask = data_dict[\"val_mask\"]\n",
    "    X = data_dict[\"X\"]\n",
    "    y = data_dict[\"y\"]\n",
    "    X_test = data_dict[\"X_test\"]\n",
    "    y_test = data_dict[\"y_test\"]\n",
    "\n",
    "    # split the validation\n",
    "    X_select_train, y_select_train, X_select_val, y_select_val = X[train_mask], y[train_mask], X[val_mask], y[val_mask]\n",
    "\n",
    "    # get the best features\n",
    "    best_features, score = forward_selection_with_validation(X_select_train, y_select_train, X_select_val, y_select_val, use_aic=True)\n",
    "\n",
    "    # get the best feature mask and split\n",
    "    X_train = X[train_mask][best_features]\n",
    "    y_train = y[train_mask]\n",
    "    X_test = X_test[best_features]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def evaluate_rrf(X_train, y_train, X_test, y_test):   \n",
    "    # Train a Random Forest Regressor\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=8)\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # score the model\n",
    "    y_test_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    # scoring\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    print(f\"Random Forest Model Performance:\")\n",
    "    print(f\"Testing  R^2: {r2_test:.4f}, RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "    # Baseline metrics (Median predictor)\n",
    "    median_test_pred = np.full_like(y_test, np.median(y_train))\n",
    "    median_r2_test = r2_score(y_test, median_test_pred)\n",
    "    median_rmse_test = np.sqrt(mean_squared_error(y_test, median_test_pred))\n",
    "    print(f\"\\nBaseline Model (Median Predictor) Performance:\")\n",
    "    print(f\"Testing  R^2: {median_r2_test:.4f}, RMSE: {median_rmse_test:.4f}\")\n",
    "\n",
    "    return r2_test, median_r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train, y_train, X_test, y_test, RRF=False):\n",
    "    if (RRF):\n",
    "        return evaluate_rrf(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # train and test\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict target values using the test set\n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse_linear = mean_squared_error(y_test, y_pred)\n",
    "    r2_linear = r2_score(y_test, y_pred)\n",
    "\n",
    "    # baseline data2\n",
    "    baseline_pred = [y_train.mean()] * len(y_test)\n",
    "\n",
    "    # baseline score\n",
    "    mse_baseline = mean_squared_error(y_test, baseline_pred)\n",
    "    r2_baseline = r2_score(y_test, baseline_pred)\n",
    "\n",
    "    # zero R\n",
    "    zero = [0] * len(y_test)\n",
    "\n",
    "    # baseline score\n",
    "    mse_zero = mean_squared_error(y_test, zero)\n",
    "    r2_zero = r2_score(y_test, zero)\n",
    "\n",
    "    # Step 9: Print comparison results\n",
    "    print(f\"Linear Model - RMSE: {np.sqrt(mse_linear):.3f}, R-squared: {r2_linear:.3f}\")\n",
    "    print(f\"Baseline Model - RMSE: {np.sqrt(mse_baseline):.3f}, R-squared: {r2_baseline:.3f}\")\n",
    "    print(f\"Zero Model - RMSE: {np.sqrt(mse_zero):.3f}, R-squared: {r2_zero:.3f}\")\n",
    "\n",
    "    return r2_linear, r2_baseline, r2_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up to year: 2, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "TRAINING_SIZE = 3\n",
    "\n",
    "max_year = int(curated_final[\"year groups\"].max())\n",
    "min_year = int(curated_final[\"year groups\"].min())\n",
    "\n",
    "best_features_list = []\n",
    "print(\"up to year: \", end=\"\")\n",
    "for curr_start_year in range(min_year, max_year-TRAINING_SIZE+1):\n",
    "    print(f\"{curr_start_year}, \", end=\"\")\n",
    "\n",
    "    # get the data dict\n",
    "    _a, _b, _c, _d, best_features = get_train_test(curated_final, curr_start_year, curr_start_year+TRAINING_SIZE, curr_start_year+TRAINING_SIZE+1, FEATURES)\n",
    "\n",
    "    best_features_list.append(best_features)\n",
    "\n",
    "flattened_features = [item for sublist in best_features_list for item in sublist]\n",
    "features_dict = dict(Counter(flattened_features))\n",
    "#sorted(features_dict.items(), key=lambda x: x[1])\n",
    "\n",
    "# get the best features, that occur in at least `count thresh` train test cycles\n",
    "COUNT_THRESH = 4\n",
    "SELECT_FEATURES_NO = [column_key for column_key, count in features_dict.items() if count >= COUNT_THRESH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -1.9872, RMSE: 0.0620\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -2.1931, RMSE: 0.0641\n",
      "3\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -2.6577, RMSE: 0.0802\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -2.9731, RMSE: 0.0836\n",
      "4\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -0.9054, RMSE: 0.0394\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -0.8491, RMSE: 0.0388\n",
      "5\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -0.7305, RMSE: 0.0278\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -0.1108, RMSE: 0.0223\n",
      "6\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -0.3269, RMSE: 0.0280\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -1.1320, RMSE: 0.0354\n",
      "7\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -1.3388, RMSE: 0.0417\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -2.8618, RMSE: 0.0536\n",
      "8\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -3.6893, RMSE: 0.0456\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -5.8241, RMSE: 0.0550\n",
      "9\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -1.2405, RMSE: 0.0310\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -1.3223, RMSE: 0.0316\n",
      "10\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -2.6283, RMSE: 0.0341\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -0.3767, RMSE: 0.0210\n",
      "11\n",
      "Random Forest Model Performance:\n",
      "Testing  R^2: -0.5265, RMSE: 0.0224\n",
      "\n",
      "Baseline Model (Median Predictor) Performance:\n",
      "Testing  R^2: -0.0039, RMSE: 0.0181\n",
      "12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m dd \u001b[38;5;241m=\u001b[39m get_data(curated_final, START_YEAR, END_YEAR, TEST_YEAR, SELECT_FEATURES_NO)\n\u001b[1;32m     10\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m dd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m\"\u001b[39m], dd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m\"\u001b[39m], dd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m\"\u001b[39m], dd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRRF\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(X_train, y_train, X_test, y_test, RRF)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(X_train, y_train, X_test, y_test, RRF\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (RRF):\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_rrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# train and test\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     lin_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36mevaluate_rrf\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_rrf\u001b[39m(X_train, y_train, X_test, y_test):   \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Train a Random Forest Regressor\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     rf_regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mrf_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# score the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     y_test_pred \u001b[38;5;241m=\u001b[39m rf_regressor\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1280\u001b[0m ):\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2, 17):\n",
    "    print(i)\n",
    "    ADD = i\n",
    "\n",
    "    START_YEAR = 0 + ADD\n",
    "    END_YEAR = 4 + ADD\n",
    "    TEST_YEAR = 5 + ADD\n",
    "\n",
    "    dd = get_data(curated_final, START_YEAR, END_YEAR, TEST_YEAR, SELECT_FEATURES_NO)\n",
    "    X_train, y_train, X_test, y_test = dd[\"X_train\"], dd[\"y_train\"], dd[\"X_test\"], dd[\"y_test\"]\n",
    "\n",
    "    evaluate(X_train, y_train, X_test, y_test, RRF=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 17):\n",
    "    print(i)\n",
    "    ADD = i\n",
    "\n",
    "    START_YEAR = 0 + ADD\n",
    "    END_YEAR = 4 + ADD\n",
    "    TEST_YEAR = 5 + ADD\n",
    "\n",
    "    dd = get_data(curated_final, START_YEAR, END_YEAR, TEST_YEAR, SELECT_FEATURES_NO)\n",
    "    X_train, y_train, X_test, y_test = dd[\"X_train\"], dd[\"y_train\"], dd[\"X_test\"], dd[\"y_test\"]\n",
    "\n",
    "    evaluate(X_train, y_train, X_test, y_test, RRF=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['housing: previous price',\n",
       " 'housing: previous count growth',\n",
       " 'housing: previous growth',\n",
       " 'housing: previous count log',\n",
       " 'population: total log',\n",
       " 'economic: trimmed mean quarterly',\n",
       " 'interaction: (studying: tertiary total (%) log) & (population: total log)',\n",
       " 'interaction: (economic: median income) & (economic: trimmed mean quarterly)']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SELECT_FEATURES = [\"housing: previous price\", \"housing: previous count growth\", \"housing: previous growth\", \"housing: previous count log\"] + \\\n",
    "                  [\"population: total log\", \"economic: trimmed mean quarterly\"] + \\\n",
    "                  [\"interaction: (studying: tertiary total (%) log) & (population: total log)\", \"interaction: (economic: median income) & (economic: trimmed mean quarterly)\"]\n",
    "SELECT_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = filter_frame(curated_final, start_year=21, end_year=23)\n",
    "test_data = pd.read_csv(f\"{RELATIVE_PATH_IN_MODELLING}/forecast_test.csv\", index_col=0)\n",
    "\n",
    "X_train, y_train, X_test = train_data[SELECT_FEATURES], train_data[\"housing: median growth\"], test_data[SELECT_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicitions</th>\n",
       "      <th>suburbs</th>\n",
       "      <th>housing: type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114625</td>\n",
       "      <td>Albert Park-Middle Park-West St Kilda</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056722</td>\n",
       "      <td>Albert Park-Middle Park-West St Kilda</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081970</td>\n",
       "      <td>Altona</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103797</td>\n",
       "      <td>Altona</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.114085</td>\n",
       "      <td>Armadale</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.044602</td>\n",
       "      <td>Williamstown</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.079324</td>\n",
       "      <td>Wodonga</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.063490</td>\n",
       "      <td>Wodonga</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.047381</td>\n",
       "      <td>Yarraville-Seddon</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.061512</td>\n",
       "      <td>Yarraville-Seddon</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicitions                                suburbs housing: type\n",
       "0        0.114625  Albert Park-Middle Park-West St Kilda          flat\n",
       "1        0.056722  Albert Park-Middle Park-West St Kilda         house\n",
       "2        0.081970                                 Altona          flat\n",
       "3        0.103797                                 Altona         house\n",
       "4        0.114085                               Armadale          flat\n",
       "..            ...                                    ...           ...\n",
       "274      0.044602                           Williamstown         house\n",
       "275      0.079324                                Wodonga          flat\n",
       "276      0.063490                                Wodonga         house\n",
       "277      0.047381                      Yarraville-Seddon          flat\n",
       "278      0.061512                      Yarraville-Seddon         house\n",
       "\n",
       "[279 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict target values using the test set\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# final frame\n",
    "results = pd.DataFrame(data={\"predicitions\": y_pred, \"suburbs\": test_data[\"suburbs\"].values, \"housing: type\": test_data[\"housing: type\"].values})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicitions</th>\n",
       "      <th>suburbs</th>\n",
       "      <th>housing: type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.286198</td>\n",
       "      <td>CBD-St Kilda Rd</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.234282</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.228233</td>\n",
       "      <td>Carlton-Parkville</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.215569</td>\n",
       "      <td>North Melbourne-West Melbourne</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.199992</td>\n",
       "      <td>Caulfield</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.197258</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.171468</td>\n",
       "      <td>South Melbourne</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.153960</td>\n",
       "      <td>Richmond-Burnley</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.152702</td>\n",
       "      <td>Footscray</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.148258</td>\n",
       "      <td>Box Hill</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicitions                         suburbs housing: type\n",
       "46       0.286198                 CBD-St Kilda Rd          flat\n",
       "228      0.234282                       Southbank          flat\n",
       "53       0.228233               Carlton-Parkville          flat\n",
       "185      0.215569  North Melbourne-West Melbourne          flat\n",
       "58       0.199992                       Caulfield          flat\n",
       "82       0.197258                       Docklands          flat\n",
       "224      0.171468                 South Melbourne          flat\n",
       "209      0.153960                Richmond-Burnley          flat\n",
       "116      0.152702                       Footscray          flat\n",
       "30       0.148258                        Box Hill          flat"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = results.nlargest(10, \"predicitions\")\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
